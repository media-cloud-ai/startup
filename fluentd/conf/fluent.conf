# fluentd/conf/fluent.conf
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

#####
# WORKERS
#####

# Filter for the multiline messages
#   As positive lookahead is used in regex, when there is no new message for
#   more than 3s, flush appends and log is sent to ElasticSearch via the label.
#   TODO : see if possible to do this in a more beautiful way.
<filter workers.**>
  @type concat
  key log
  stream_identity_key container_id
  flush_interval 3
  timeout_label @TIMEOUTFLUSH
  multiline_start_regexp /^[0-9:\.\s-]*UTC/
  multiline_end_regexp /[^\n](?=[0-9:\.\s-]*UTC)$/
</filter>

# Filter for the log messages
#   Break the log message into different key:value pairs
<filter workers.**>
  @type parser
  key_name log
  <parse>
    @type regexp
    expression /^(?<logtime>[0-9:\.\s-]*UTC) - (?<container_id>[a-z0-9]*) - (?<job>[a-z_]*) - (?<workflow_id>-?\d*) - (?<severity_level>INFO|ERROR|FATAL|WARN|DEBUG) - (?<message>.*)$/m
    time_key logtime
    types id:integer
  </parse>
</filter>

# Copy the logs to ElasticSearch
<match workers.**>
  @type copy
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix fluentd-workers
    logstash_dateformat %Y%m%d
    include_tag_key true
    type_name access_log
    tag_key @log_name
    flush_interval 1s
  </store>
  <store>
    @type stdout
  </store>
</match>


#####
# BACKEND
#####

<filter backend.**>
  @type concat
  key log
  stream_identity_key container_id
  flush_interval 3
  timeout_label @TIMEOUTFLUSH
  multiline_start_regexp /^[0-9:\.]{12}\s/
  multiline_end_regexp /(?=[0-9:\.]{12}\s)$/
</filter>

<filter backend.**>
  @type parser
  key_name log
  <parse>
    @type multi_format
    <pattern>
      format regexp
      expression /^(?<logtime>[0-9:\.]{12}) (?<request>request_id=[a-zA-Z-0-9_\-]{1,20}) (?<severity>\[[a-z]*\]) (?<message>.*)$/m
      time_key logtime
      time_format %H:%M:%S
    </pattern>
    <pattern>
      format regexp
      expression /^(?<logtime>[0-9:\.]{12}) (?<severity>\[[a-z]*\]) (?<message>.*)$/m
      time_key logtime
      time_format %H:%M:%S
    </pattern>
  </parse>
</filter>

<match backend.**>
  @type copy
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix fluentd-backend
    logstash_dateformat %Y%m%d
    include_tag_key true
    type_name access_log
    tag_key @log_name
    flush_interval 1s
  </store>
</match>


#####
# TIMEOUT LABEL
#####

# Repeated block for timeout flush
<label @TIMEOUTFLUSH>

  #####
  # WORKERS
  #####

  <filter workers.**>
    @type parser
    key_name log
    <parse>
      @type regexp
      expression /^(?<logtime>[0-9:\.\s-]*UTC) - (?<container_id>[a-z0-9]*) - (?<job>[a-z_]*) - (?<workflow_id>-?\d*) - (?<severity_level>INFO|ERROR|FATAL|WARN|DEBUG) - (?<message>.*)$/m
      time_key logtime
      # time_format %Y-%m-%d %H:%M:%S
      types id:integer
    </parse>
  </filter>

  <match workers.**>
    @type copy
    <store>
      @type elasticsearch
      host elasticsearch
      port 9200
      logstash_format true
      logstash_prefix fluentd-workers
      logstash_dateformat %Y%m%d
      include_tag_key true
      type_name access_log
      tag_key @log_name
      flush_interval 1s
    </store>
  </match>

  #####
  # BACKEND
  #####

  <filter backend.**>
    @type parser
    key_name log
    <parse>
      @type multi_format
      <pattern>
        format regexp
        expression /^(?<logtime>[0-9:\.]{12}) (?<request>request_id=[a-zA-Z-0-9_\-]{1,20}) (?<severity>\[[a-z]*\]) (?<message>.*)$/m
        time_key logtime
        time_format %H:%M:%S
      </pattern>
      <pattern>
        format regexp
        expression /^(?<logtime>[0-9:\.]{12}) (?<severity>\[[a-z]*\]) (?<message>.*)$/m
        time_key logtime
        time_format %H:%M:%S
      </pattern>
    </parse>
  </filter>

  # Copy the logs to ElasticSearch
  <match backend.**>
    @type copy
    <store>
      @type elasticsearch
      host elasticsearch
      port 9200
      logstash_format true
      logstash_prefix fluentd-backend
      logstash_dateformat %Y%m%d
      include_tag_key true
      type_name access_log
      tag_key @log_name
      flush_interval 1s
    </store>
  </match>
</label>
